/**
 * @note This parser header file is generated from a template.
 * Any modifications to this file will be overwritten.
 * Please do not edit this file directly.
 *
 * @note 此文件是从模板生成的。
 * 任何对该文件的修改都将被覆盖。
 * 请不要直接编辑此文件。
 */

#ifndef __GRAMMAR_SYNTAX_H__
#define __GRAMMAR_SYNTAX_H__

#include "alioth/ast.h"

namespace grammar {

constexpr alioth::SymbolID LEAD = 1;
constexpr alioth::SymbolID LT = 2;
constexpr alioth::SymbolID GT = 3;
constexpr alioth::SymbolID UNION = 4;
constexpr alioth::SymbolID DEFINE = 5;
constexpr alioth::SymbolID IGNORE = 6;
constexpr alioth::SymbolID AT = 7;
constexpr alioth::SymbolID SEMICOLON = 8;
constexpr alioth::SymbolID COLON = 9;
constexpr alioth::SymbolID COMMA = 10;
constexpr alioth::SymbolID DOT = 11;
constexpr alioth::SymbolID UNFOLD = 12;
constexpr alioth::SymbolID LBRACE = 13;
constexpr alioth::SymbolID RBRACE = 14;
constexpr alioth::SymbolID LPAREN = 15;
constexpr alioth::SymbolID RPAREN = 16;
constexpr alioth::SymbolID LBRACKET = 17;
constexpr alioth::SymbolID RBRACKET = 18;
constexpr alioth::SymbolID EMPTY = 19;
constexpr alioth::SymbolID IMPORT = 20;
constexpr alioth::SymbolID AS = 21;
constexpr alioth::SymbolID ANNOTATE = 22;
constexpr alioth::SymbolID WITH = 23;
constexpr alioth::SymbolID JNULL = 24;
constexpr alioth::SymbolID TRUE = 25;
constexpr alioth::SymbolID FALSE = 26;
constexpr alioth::SymbolID STRING = 27;
constexpr alioth::SymbolID NUMBER = 28;
constexpr alioth::SymbolID ID = 29;
constexpr alioth::SymbolID REGEX = 30;
constexpr alioth::SymbolID COMMENT = 31;
constexpr alioth::SymbolID SPACE = 32;

struct Annotation; // SymbolID = 44; Accepts: [44]
struct Attribute; // SymbolID = 66; Accepts: [66]
struct EmptyFormula; // SymbolID = 53; Accepts: [53]
struct Field; // SymbolID = 63; Accepts: [63]
struct Formula; // SymbolID = 52; Accepts: [52, 54]
struct Grammar; // SymbolID = 34; Accepts: [34]
struct Import; // SymbolID = 42; Accepts: [42]
struct Json; // SymbolID = 41; Accepts: [41, 56, 57, 58, 59, 60, 61]
struct Ntrm; // SymbolID = 48; Accepts: [48]
struct Option; // SymbolID = 40; Accepts: [40]
struct Selector; // SymbolID = 51; Accepts: [51]
struct Symbol; // SymbolID = 55; Accepts: [55]
struct Term; // SymbolID = 43; Accepts: [43]


struct Annotation {
  std::vector<Attribute> attributes() const;
  std::vector<Selector> selectors() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Attribute {
  alioth::AST key() const;
  alioth::AST of() const;
  Json value() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct EmptyFormula {
  alioth::AST empty() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Field {
  alioth::AST key() const;
  Json value() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Formula {
  std::vector<Attribute> attributes() const;
  std::vector<Symbol> symbols() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Grammar {
  std::vector<Annotation> annotations() const;
  std::vector<alioth::AST> external_annotations() const;
  std::vector<Import> imports() const;
  std::vector<Ntrm> ntrms() const;
  std::vector<Option> options() const;
  std::vector<Term> terms() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Import {
  alioth::AST alias() const;
  alioth::AST lang() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Json {
  std::vector<Json> array() const;
  alioth::AST boolean() const;
  alioth::AST empty_array() const;
  alioth::AST empty_object() const;
  alioth::AST null() const;
  alioth::AST number() const;
  std::vector<Field> object() const;
  alioth::AST string() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Ntrm {
  alioth::AST form() const;
  std::vector<alioth::AST> formulas() const;
  alioth::AST name() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Option {
  alioth::AST key() const;
  Json value() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Selector {
  alioth::AST form() const;
  alioth::AST symbol() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Symbol {
  alioth::AST attr() const;
  alioth::AST name() const;
  alioth::AST optional() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};

struct Term {
  std::vector<Attribute> attributes() const;
  std::vector<alioth::AST> contexts() const;
  alioth::AST ignore() const;
  alioth::AST name() const;
  alioth::AST regex() const;
  alioth::AST node{};

  operator alioth::AST() const { return node; }
  operator bool() const { return node != nullptr; }
  alioth::ASTNode* operator->() const { return node.get(); }
  alioth::ASTNode& operator*() const { return *node; }
};


}

namespace alioth {
template<>
inline grammar::Annotation alioth::ASTNode::As<grammar::Annotation>() {
  switch(id) {
    case 44:
    return grammar::Annotation{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Attribute alioth::ASTNode::As<grammar::Attribute>() {
  switch(id) {
    case 66:
    return grammar::Attribute{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::EmptyFormula alioth::ASTNode::As<grammar::EmptyFormula>() {
  switch(id) {
    case 53:
    return grammar::EmptyFormula{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Field alioth::ASTNode::As<grammar::Field>() {
  switch(id) {
    case 63:
    return grammar::Field{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Formula alioth::ASTNode::As<grammar::Formula>() {
  switch(id) {
    case 52:case 54:
    return grammar::Formula{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Grammar alioth::ASTNode::As<grammar::Grammar>() {
  switch(id) {
    case 34:
    return grammar::Grammar{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Import alioth::ASTNode::As<grammar::Import>() {
  switch(id) {
    case 42:
    return grammar::Import{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Json alioth::ASTNode::As<grammar::Json>() {
  switch(id) {
    case 41:case 56:case 57:case 58:case 59:case 60:case 61:
    return grammar::Json{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Ntrm alioth::ASTNode::As<grammar::Ntrm>() {
  switch(id) {
    case 48:
    return grammar::Ntrm{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Option alioth::ASTNode::As<grammar::Option>() {
  switch(id) {
    case 40:
    return grammar::Option{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Selector alioth::ASTNode::As<grammar::Selector>() {
  switch(id) {
    case 51:
    return grammar::Selector{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Symbol alioth::ASTNode::As<grammar::Symbol>() {
  switch(id) {
    case 55:
    return grammar::Symbol{shared_from_this()};
  default:
    return {};
  }
}

template<>
inline grammar::Term alioth::ASTNode::As<grammar::Term>() {
  switch(id) {
    case 43:
    return grammar::Term{shared_from_this()};
  default:
    return {};
  }
}


template<>
inline Syntax SyntaxOf<grammar::Grammar>() {
  static auto syntax = []{
    using namespace alioth;
    using namespace nlohmann;
    auto lex = Lexicon::Builder("grammar");
    lex.Define("LEAD", R"(->)"_regex);
    lex.Annotate("LEAD", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("LT", R"(<)"_regex);
    lex.Annotate("LT", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("GT", R"(>)"_regex);
    lex.Annotate("GT", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("UNION", R"(\|)"_regex);
    lex.Annotate("UNION", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("DEFINE", R"(=)"_regex);
    lex.Annotate("DEFINE", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("IGNORE", R"(\?)"_regex);
    lex.Annotate("IGNORE", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("AT", R"(@)"_regex);
    lex.Annotate("AT", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("SEMICOLON", R"(;)"_regex);
    lex.Annotate("SEMICOLON", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("COLON", R"(:)"_regex);
    lex.Annotate("COLON", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("COMMA", R"(,)"_regex);
    lex.Annotate("COMMA", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("DOT", R"(\.)"_regex);
    lex.Annotate("DOT", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("UNFOLD", R"(\.\.\.)"_regex);
    lex.Annotate("UNFOLD", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("LBRACE", R"({)"_regex);
    lex.Annotate("LBRACE", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("RBRACE", R"(})"_regex);
    lex.Annotate("RBRACE", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("LPAREN", R"(\()"_regex);
    lex.Annotate("LPAREN", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("RPAREN", R"(\))"_regex);
    lex.Annotate("RPAREN", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("LBRACKET", R"(\[)"_regex);
    lex.Annotate("LBRACKET", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("RBRACKET", R"(])"_regex);
    lex.Annotate("RBRACKET", "tokenize", R"({"type":"operator"})"_json);
    
    lex.Define("EMPTY", R"(%empty)"_regex);
    lex.Annotate("EMPTY", "tokenize", R"({"type":"keyword"})"_json);
    
    lex.Define("IMPORT", R"(import)"_regex, { "keyword",  });
    
    lex.Define("AS", R"(as)"_regex, { "keyword",  });
    
    lex.Define("ANNOTATE", R"(annotate)"_regex, { "keyword",  });
    
    lex.Define("WITH", R"(with)"_regex, { "keyword",  });
    
    lex.Define("JNULL", R"(null)"_regex, { "json",  });
    lex.Annotate("JNULL", "tokenize", R"({"type":"keyword"})"_json);
    
    lex.Define("TRUE", R"(true)"_regex, { "json",  });
    lex.Annotate("TRUE", "tokenize", R"({"type":"keyword"})"_json);
    
    lex.Define("FALSE", R"(false)"_regex, { "json",  });
    lex.Annotate("FALSE", "tokenize", R"({"type":"keyword"})"_json);
    
    lex.Define("STRING", R"(\"([^\"\n\\]|\\[^\n])*\")"_regex, { "json",  });
    lex.Annotate("STRING", "tokenize", R"({"type":"string"})"_json);
    
    lex.Define("NUMBER", R"(-?(0|[1-9]\d*)(\.\d+)?([eE][+-]?\d+)?)"_regex, { "json",  });
    lex.Annotate("NUMBER", "tokenize", R"({"type":"number"})"_json);
    
    lex.Define("ID", R"([a-zA-Z_]\w*)"_regex);
    
    lex.Define("REGEX", R"(\/([^\\\/]|\\[^\n])+\/)"_regex);
    lex.Annotate("REGEX", "tokenize", R"({"type":"regexp"})"_json);
    
    lex.Define("COMMENT", R"(#[^\n]*\n)"_regex);
    lex.Annotate("COMMENT", "tokenize", R"({"type":"comment"})"_json);
    
    lex.Define("SPACE", R"(\s+)"_regex);
    
    
    auto syntax = Syntactic::Builder(lex.Build());
    syntax.Ignore("COMMENT");
    syntax.Ignore("SPACE");
    
    syntax.Formula("grammar").Symbol("options", "...").Symbol("terms", "...").Symbol("ntrms", "...").Commit();
    syntax.Formula("grammar").Symbol("options", "...").Symbol("imports", "...").Symbol("terms", "...").Symbol("ntrms", "...").Commit();
    syntax.Formula("grammar").Symbol("options", "...").Symbol("annotate", "...").Symbol("terms", "...").Symbol("ntrms", "...").Commit();
    syntax.Formula("grammar").Symbol("options", "...").Symbol("imports", "...").Symbol("annotate", "...").Symbol("terms", "...").Symbol("ntrms", "...").Commit();
    syntax.Formula("options").Symbol("option", "options").Commit();
    syntax.Formula("options").Symbol("options", "...").Symbol("option", "options").Commit();
    syntax.Formula("option").Symbol("ID", "key").Symbol("COLON").Symbol("json", "value")
      .Annotate("key", "tokenize", R"({"modifier":["definition"],"type":"variable"})"_json)
      .Commit();
    syntax.Formula("imports").Symbol("import", "imports").Commit();
    syntax.Formula("imports").Symbol("imports", "...").Symbol("import", "imports").Commit();
    syntax.Formula("import").Symbol("IMPORT").Symbol("STRING", "lang").Commit();
    syntax.Formula("import").Symbol("IMPORT").Symbol("STRING", "lang").Symbol("AS").Symbol("ID", "alias").Commit();
    syntax.Formula("annotate").Symbol("ANNOTATE").Symbol("WITH").Symbol("STRING", "external_annotations").Commit();
    syntax.Formula("annotate").Symbol("annotate", "...").Symbol("STRING", "external_annotations").Commit();
    syntax.Formula("terms").Symbol("term", "terms").Commit();
    syntax.Formula("terms").Symbol("terms", "...").Symbol("term", "terms").Commit();
    syntax.Formula("terms").Symbol("terms", "...").Symbol("annotation", "annotations").Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("DEFINE").Symbol("REGEX", "regex")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("contexts", "...").Symbol("DEFINE").Symbol("REGEX", "regex")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("IGNORE", "ignore").Symbol("DEFINE").Symbol("REGEX", "regex")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("contexts", "...").Symbol("IGNORE", "ignore").Symbol("DEFINE").Symbol("REGEX", "regex")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("DEFINE").Symbol("REGEX", "regex").Symbol("annotation_body", "...")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("contexts", "...").Symbol("DEFINE").Symbol("REGEX", "regex").Symbol("annotation_body", "...")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("IGNORE", "ignore").Symbol("DEFINE").Symbol("REGEX", "regex").Symbol("annotation_body", "...")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("term").Symbol("ID", "name").Symbol("contexts", "...").Symbol("IGNORE", "ignore").Symbol("DEFINE").Symbol("REGEX", "regex").Symbol("annotation_body", "...")
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("contexts").Symbol("LT").Symbol("context_list", "...").Symbol("GT").Commit();
    syntax.Formula("context_list").Symbol("ID", "contexts")
      .Annotate("contexts", "tokenize", R"({"modifier":["definition"],"type":"decorator"})"_json)
      .Commit();
    syntax.Formula("context_list").Symbol("context_list", "...").Symbol("COMMA").Symbol("ID", "contexts")
      .Annotate("contexts", "tokenize", R"({"modifier":["definition"],"type":"decorator"})"_json)
      .Commit();
    syntax.Formula("ntrms").Symbol("ntrm", "ntrms").Commit();
    syntax.Formula("ntrms").Symbol("ntrms", "...").Symbol("ntrm", "ntrms").Commit();
    syntax.Formula("ntrms").Symbol("ntrms", "...").Symbol("annotation", "annotations").Commit();
    syntax.Formula("ntrm").Symbol("ID", "name").Symbol("LEAD").Symbol("formula_group", "...").Symbol("SEMICOLON")
      .Annotate("form", "tokenize", R"({"modifier":["definition"],"type":"decorator"})"_json)
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("ntrm").Symbol("ID", "name").Symbol("DOT").Symbol("ID", "form").Symbol("LEAD").Symbol("formula_group", "...").Symbol("SEMICOLON")
      .Annotate("form", "tokenize", R"({"modifier":["definition"],"type":"decorator"})"_json)
      .Annotate("name", "tokenize", R"({"modifier":["definition"],"type":"class"})"_json)
      .Commit();
    syntax.Formula("annotation").Symbol("selectors", "...").Symbol("annotation_body", "...").Commit();
    syntax.Formula("annotation").Symbol("selectors", "...").Symbol("annotation_body", "...").Symbol("SEMICOLON").Commit();
    syntax.Formula("selectors").Symbol("selector", "selectors").Commit();
    syntax.Formula("selectors").Symbol("selectors", "...").Symbol("COMMA").Symbol("selector", "selectors").Commit();
    syntax.Formula("selector").Symbol("ID", "symbol")
      .Annotate("form", "tokenize", R"({"type":"decorator"})"_json)
      .Annotate("symbol", "tokenize", R"({"type":"class"})"_json)
      .Commit();
    syntax.Formula("selector").Symbol("ID", "symbol").Symbol("DOT").Symbol("ID", "form")
      .Annotate("form", "tokenize", R"({"type":"decorator"})"_json)
      .Annotate("symbol", "tokenize", R"({"type":"class"})"_json)
      .Commit();
    syntax.Formula("formula_group").Symbol("formula", "formulas").Commit();
    syntax.Formula("formula_group").Symbol("empty_formula", "formulas").Commit();
    syntax.Formula("formula_group").Symbol("formula_group", "...").Symbol("UNION").Symbol("formula", "formulas").Commit();
    syntax.Formula("formula_group").Symbol("formula_group", "...").Symbol("UNION").Symbol("empty_formula", "formulas").Commit();
    syntax.Formula("formula").Symbol("formula_body", "...").Commit();
    syntax.Formula("formula").Symbol("formula_body", "...").Symbol("annotation_body", "...").Commit();
    syntax.Formula("formula_body").Symbol("symbol", "symbols").Commit();
    syntax.Formula("formula_body").Symbol("formula_body", "...").Symbol("symbol", "symbols").Commit();
    syntax.Formula("empty_formula").Symbol("EMPTY", "empty").Commit();
    syntax.Formula("symbol").Symbol("ID", "name")
      .Annotate("attr", "tokenize", R"({"modifier":["definition"],"type":"property"})"_json)
      .Annotate("name", "tokenize", R"({"type":"string"})"_json)
      .Commit();
    syntax.Formula("symbol").Symbol("ID", "name").Symbol("IGNORE", "optional")
      .Annotate("attr", "tokenize", R"({"modifier":["definition"],"type":"property"})"_json)
      .Annotate("name", "tokenize", R"({"type":"string"})"_json)
      .Commit();
    syntax.Formula("symbol").Symbol("ID", "name").Symbol("AT").Symbol("ID", "attr")
      .Annotate("attr", "tokenize", R"({"modifier":["definition"],"type":"property"})"_json)
      .Annotate("name", "tokenize", R"({"type":"string"})"_json)
      .Commit();
    syntax.Formula("symbol").Symbol("ID", "name").Symbol("IGNORE", "optional").Symbol("AT").Symbol("ID", "attr")
      .Annotate("attr", "tokenize", R"({"modifier":["definition"],"type":"property"})"_json)
      .Annotate("name", "tokenize", R"({"type":"string"})"_json)
      .Commit();
    syntax.Formula("symbol").Symbol("UNFOLD", "attr").Symbol("ID", "name")
      .Annotate("attr", "tokenize", R"({"modifier":["definition"],"type":"property"})"_json)
      .Annotate("name", "tokenize", R"({"type":"string"})"_json)
      .Commit();
    syntax.Formula("symbol").Symbol("UNFOLD", "attr").Symbol("ID", "name").Symbol("IGNORE", "optional")
      .Annotate("attr", "tokenize", R"({"modifier":["definition"],"type":"property"})"_json)
      .Annotate("name", "tokenize", R"({"type":"string"})"_json)
      .Commit();
    syntax.Formula("json").Symbol("object", "...").Commit();
    syntax.Formula("json").Symbol("array", "...").Commit();
    syntax.Formula("json").Symbol("string", "...").Commit();
    syntax.Formula("json").Symbol("number", "...").Commit();
    syntax.Formula("json").Symbol("boolean", "...").Commit();
    syntax.Formula("json").Symbol("null", "...").Commit();
    syntax.Formula("object").Symbol("LBRACE", "empty_object").Symbol("RBRACE").Commit();
    syntax.Formula("object").Symbol("LBRACE").Symbol("fields", "...").Symbol("RBRACE").Commit();
    syntax.Formula("fields").Symbol("field", "object").Commit();
    syntax.Formula("fields").Symbol("fields", "...").Symbol("COMMA").Symbol("field", "object").Commit();
    syntax.Formula("field").Symbol("STRING", "key").Symbol("COLON").Symbol("json", "value").Commit();
    syntax.Formula("array").Symbol("LBRACKET", "empty_array").Symbol("RBRACKET").Commit();
    syntax.Formula("array").Symbol("LBRACKET").Symbol("elements", "...").Symbol("RBRACKET").Commit();
    syntax.Formula("elements").Symbol("json", "array").Commit();
    syntax.Formula("elements").Symbol("elements", "...").Symbol("COMMA").Symbol("json", "array").Commit();
    syntax.Formula("string").Symbol("STRING", "string").Commit();
    syntax.Formula("number").Symbol("NUMBER", "number").Commit();
    syntax.Formula("boolean").Symbol("TRUE", "boolean").Commit();
    syntax.Formula("boolean").Symbol("FALSE", "boolean").Commit();
    syntax.Formula("null").Symbol("JNULL", "null").Commit();
    syntax.Formula("annotation_body").Symbol("LBRACE").Symbol("attributes", "...").Symbol("RBRACE").Commit();
    syntax.Formula("attributes").Symbol("attribute", "attributes").Commit();
    syntax.Formula("attributes").Symbol("attributes", "...").Symbol("COMMA").Symbol("attribute", "attributes").Commit();
    syntax.Formula("attribute").Symbol("ID", "key").Symbol("COLON").Symbol("json", "value")
      .Annotate("key", "tokenize", R"({"modifier":["modification"],"type":"property"})"_json)
      .Annotate("of", "tokenize", R"({"type":"property"})"_json)
      .Commit();
    syntax.Formula("attribute").Symbol("ID", "of").Symbol("DOT").Symbol("ID", "key").Symbol("COLON").Symbol("json", "value")
      .Annotate("key", "tokenize", R"({"modifier":["modification"],"type":"property"})"_json)
      .Annotate("of", "tokenize", R"({"type":"property"})"_json)
      .Commit();
    
    return syntax.Build();
  }();

  return syntax;
}
}

namespace grammar {

inline std::vector<Attribute> Annotation::attributes() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("attributes"), [](auto n) { return n->template As<Attribute>(); }); }
inline std::vector<Selector> Annotation::selectors() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("selectors"), [](auto n) { return n->template As<Selector>(); }); }

inline alioth::AST Attribute::key() const { return node->Attr("key"); }
inline alioth::AST Attribute::of() const { return node->Attr("of"); }
inline Json Attribute::value() const { return node->Attr("value")->template As<Json>(); }

inline alioth::AST EmptyFormula::empty() const { return node->Attr("empty"); }

inline alioth::AST Field::key() const { return node->Attr("key"); }
inline Json Field::value() const { return node->Attr("value")->template As<Json>(); }

inline std::vector<Attribute> Formula::attributes() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("attributes"), [](auto n) { return n->template As<Attribute>(); }); }
inline std::vector<Symbol> Formula::symbols() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("symbols"), [](auto n) { return n->template As<Symbol>(); }); }

inline std::vector<Annotation> Grammar::annotations() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("annotations"), [](auto n) { return n->template As<Annotation>(); }); }
inline std::vector<alioth::AST> Grammar::external_annotations() const { return node->Attrs("external_annotations"); }
inline std::vector<Import> Grammar::imports() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("imports"), [](auto n) { return n->template As<Import>(); }); }
inline std::vector<Ntrm> Grammar::ntrms() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("ntrms"), [](auto n) { return n->template As<Ntrm>(); }); }
inline std::vector<Option> Grammar::options() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("options"), [](auto n) { return n->template As<Option>(); }); }
inline std::vector<Term> Grammar::terms() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("terms"), [](auto n) { return n->template As<Term>(); }); }

inline alioth::AST Import::alias() const { return node->Attr("alias"); }
inline alioth::AST Import::lang() const { return node->Attr("lang"); }

inline std::vector<Json> Json::array() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("array"), [](auto n) { return n->template As<Json>(); }); }
inline alioth::AST Json::boolean() const { return node->Attr("boolean"); }
inline alioth::AST Json::empty_array() const { return node->Attr("empty_array"); }
inline alioth::AST Json::empty_object() const { return node->Attr("empty_object"); }
inline alioth::AST Json::null() const { return node->Attr("null"); }
inline alioth::AST Json::number() const { return node->Attr("number"); }
inline std::vector<Field> Json::object() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("object"), [](auto n) { return n->template As<Field>(); }); }
inline alioth::AST Json::string() const { return node->Attr("string"); }

inline alioth::AST Ntrm::form() const { return node->Attr("form"); }
inline std::vector<alioth::AST> Ntrm::formulas() const { return node->Attrs("formulas"); }
inline alioth::AST Ntrm::name() const { return node->Attr("name"); }

inline alioth::AST Option::key() const { return node->Attr("key"); }
inline Json Option::value() const { return node->Attr("value")->template As<Json>(); }

inline alioth::AST Selector::form() const { return node->Attr("form"); }
inline alioth::AST Selector::symbol() const { return node->Attr("symbol"); }

inline alioth::AST Symbol::attr() const { return node->Attr("attr"); }
inline alioth::AST Symbol::name() const { return node->Attr("name"); }
inline alioth::AST Symbol::optional() const { return node->Attr("optional"); }

inline std::vector<Attribute> Term::attributes() const { return alioth::generic::collect<alioth::generic::multiple>(node->Attrs("attributes"), [](auto n) { return n->template As<Attribute>(); }); }
inline std::vector<alioth::AST> Term::contexts() const { return node->Attrs("contexts"); }
inline alioth::AST Term::ignore() const { return node->Attr("ignore"); }
inline alioth::AST Term::name() const { return node->Attr("name"); }
inline alioth::AST Term::regex() const { return node->Attr("regex"); }



}

#endif